"""A prototype for the script used to gather trajectories
from inputs generated by real players.

Use:
    A to push the cart to the left
    D to push the cart to the right
    K to save generated trajectory

Todo:
  - TODO(Pawel): Add saving trajectory under a specified path.
  - TODO(Pawel): Read the model from a specified path.
"""
from typing import List, Protocol, Tuple

import gym.envs.classic_control.cartpole as cp
import numpy as np
from pynput import keyboard

import cartpole.nn as cnn


class TransitionFunction(Protocol):
    def step(self, state: np.ndarray, action: int) -> Tuple[np.ndarray, bool]:
        ...


class RealEnv(TransitionFunction):
    def __init__(self, always_on: bool = False) -> None:
        """
        Args:
            always_on: `done` is never returned

        Note:
            This may be problematic, as we don't see the cart in the screen anymore.
        """
        self.env = cp.CartPoleEnv()
        self.always_on = always_on

    def step(self, state: np.ndarray, action: int) -> Tuple[np.ndarray, bool]:
        self.env.state = state
        new_state, _, done, _ = self.env.step(action)
        new_state = np.asarray(new_state)

        if self.always_on:
            return new_state, False
        else:
            return new_state, done


class FakeEnv(TransitionFunction):
    def __init__(self, cloner: cnn.NeuralCartCloner) -> None:
        self.cloner = cloner

    def step(self, state: np.ndarray, action: int) -> Tuple[np.ndarray, bool]:
        net_input = cnn._net_input(state=state, action=action)
        output = self.cloner(net_input)

        new_state = output.detach().numpy()
        # TODO(Pawel): Teach cloner to end the game?
        return new_state, False


def main(transition_function: TransitionFunction) -> None:
    env = cp.CartPoleEnv()
    env.reset()

    states: List[np.ndarray] = [np.asarray(env.state)]
    actions: List[int] = []

    def on_press(key):
        try:
            k = key.char
        except AttributeError:
            return
        action = 0
        if k == "a":
            action = 0
        elif k == "d":
            action = 1
        elif k == "k":
            env.close()
            return False

        actions.append(action)

        new_state, done = transition_function.step(state=states[-1], action=action)

        states.append(new_state)
        # Render new state
        env.state = new_state
        env.render()

        # If the simulator can't proceed anymore, we finish the simulation.
        if done:
            env.close()
            return False

    with keyboard.Listener(on_press=on_press) as listener:
        listener.join()

    env.close()

    np.savetxt("states.csv", states)
    np.savetxt("actions.csv", actions)


if __name__ == "__main__":
    transition_function = RealEnv(always_on=True)
    main(transition_function)
